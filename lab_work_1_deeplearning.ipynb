{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fLBWWLXfce5",
        "outputId": "a0953cf9-6859-4fc4-e102-b92cd6b82cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Dec  7 11:16:44 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8              12W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOIb_V6-4EpG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "transform=transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                             ])\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)"
      ],
      "metadata": {
        "id": "3MfBETxR4Ll1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#spliting the trainset into 80% training set and 20% validation set\n",
        "train_num =int(len(trainset)*0.8)\n",
        "val_num =len(trainset)-train_num\n",
        "trainset,valset=torch.utils.data.random_split(trainset,[train_num,val_num])\n",
        "len(trainset),len(valset)"
      ],
      "metadata": {
        "id": "M51rfEFX4Ln6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0e0316-1887-4c5d-c4e0-69411016d2f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48000, 12000)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the data\n",
        "train_loader=torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "val_loader=torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)\n",
        "test_loader=torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "1-81LPH14LqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter=next(iter(train_loader))\n",
        "images,labels=dataiter\n",
        "print(images.shape,labels.shape)\n",
        "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "print(classes[labels[0]])\n",
        "plt.imshow(images[0].squeeze(), cmap='gray')# Squeeze the image to remove the channel dimension\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8M5uaVhk4Lst",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "0d8cd730-b39d-4b47-abd6-c317c100f515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "Trouser\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(trainset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "class FeedforwardNeuralNetModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(FeedforwardNeuralNetModel, self).__init__()\n",
        "        # Linear function 1: 784 --> 100\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        # Non-linearity 1\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        # Linear function 2: 100 --> 100\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        # Non-linearity 2\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        # Linear function 3: 100 --> 100\n",
        "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        # Non-linearity 3\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        # Linear function 4 (readout): 100 --> 10\n",
        "        self.fc4 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Linear function 1\n",
        "        out = self.fc1(x)\n",
        "        # Non-linearity 1\n",
        "        out = self.relu1(out)\n",
        "\n",
        "        # Linear function 2\n",
        "        out = self.fc2(out)\n",
        "        # Non-linearity 2\n",
        "        out = self.relu2(out)\n",
        "\n",
        "        # Linear function 2\n",
        "        out = self.fc3(out)\n",
        "        # Non-linearity 2\n",
        "        out = self.relu3(out)\n",
        "\n",
        "        # Linear function 4 (readout)\n",
        "        out = self.fc4(out)\n",
        "        return out\n",
        "'''\n",
        "STEP 4: INSTANTIATE MODEL CLASS\n",
        "'''\n",
        "input_dim = 28*28\n",
        "hidden_dim = 100\n",
        "output_dim = 10\n",
        "\n",
        "model = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)\n",
        "\n",
        "#######################\n",
        "#  USE GPU FOR MODEL  #\n",
        "#######################\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "'''\n",
        "STEP 5: INSTANTIATE LOSS CLASS\n",
        "'''\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "'''\n",
        "STEP 6: INSTANTIATE OPTIMIZER CLASS\n",
        "'''\n",
        "learning_rate = 0.1\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "'''\n",
        "STEP 7: TRAIN THE MODEL\n",
        "'''\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        #######################\n",
        "        #  USE GPU FOR MODEL  #\n",
        "        #######################\n",
        "        images = images.view(-1, 28*28).requires_grad_().to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "                #######################\n",
        "                #  USE GPU FOR MODEL  #\n",
        "                #######################\n",
        "                images = images.view(-1, 28*28).requires_grad_().to(device)\n",
        "\n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        "\n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        "\n",
        "                #######################\n",
        "                #  USE GPU FOR MODEL  #\n",
        "                #######################\n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "\n",
        "            # Print Loss\n",
        "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
      ],
      "metadata": {
        "id": "wdDzhu-I4Lu9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10ca4494-05b1-4346-8ada-88b5ebe67b3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 500. Loss: 0.3688867390155792. Accuracy: 80.2300033569336\n",
            "Iteration: 1000. Loss: 0.6845625042915344. Accuracy: 81.95999908447266\n",
            "Iteration: 1500. Loss: 0.48412448167800903. Accuracy: 84.66999816894531\n",
            "Iteration: 2000. Loss: 0.1497209370136261. Accuracy: 84.91999816894531\n",
            "Iteration: 2500. Loss: 0.21496039628982544. Accuracy: 85.62999725341797\n",
            "Iteration: 3000. Loss: 0.28281915187835693. Accuracy: 85.9800033569336\n",
            "Iteration: 3500. Loss: 0.2649548649787903. Accuracy: 86.41000366210938\n",
            "Iteration: 4000. Loss: 0.48994797468185425. Accuracy: 85.80000305175781\n",
            "Iteration: 4500. Loss: 0.36336779594421387. Accuracy: 86.43000030517578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "batch_size = 100\n",
        "n_iters = 3000\n",
        "num_epochs = n_iters / (len(trainset) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.query = nn.Linear(embed_dim, embed_dim)\n",
        "        self.key = nn.Linear(embed_dim, embed_dim)\n",
        "        self.value = nn.Linear(embed_dim, embed_dim)\n",
        "        self.scale = embed_dim ** 0.5\n",
        "\n",
        "    def forward(self, x):\n",
        "        Q = self.query(x)\n",
        "        K = self.key(x)\n",
        "        V = self.value(x)\n",
        "        w=torch.matmul(Q,K.T)/self.scale\n",
        "        w=torch.softmax(w,dim=1)\n",
        "        V = torch.matmul(w, V)\n",
        "        return V\n",
        "class MLPWithAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLPWithAttention, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.embedding = nn.Linear(28 * 28, 512)  # Embedding layer\n",
        "        self.bn1 = nn.BatchNorm1d(512)  # Batch normalization\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.3)  # Dropout layer\n",
        "\n",
        "        self.attention = SelfAttention(512)  # Self-Attention layer\n",
        "        self.fc2 = nn.Linear(512, 128)  # Second dense layer\n",
        "        self.bn2 = nn.BatchNorm1d(128)  # Batch normalization\n",
        "        self.dropout2 = nn.Dropout(0.3)  # Dropout layer\n",
        "        self.fc3 = nn.Linear(128, 10)  # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten input image\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        # Compute embeddings\n",
        "        x = self.embedding(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        # Apply self-attention\n",
        "        x = self.attention(x)\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = self.fc2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)  # Raw logits for CrossEntropyLoss\n",
        "        return x\n",
        "\n",
        "\n",
        "# Replace FeedforwardNeuralNetModel with MLPWithAttention\n",
        "model = MLPWithAttention()\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.01  # Reduced learning rate for stability\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Use GPU for data if available\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Clear gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        iter += 1\n",
        "\n",
        "        if iter % 500 == 0:\n",
        "            # Calculate accuracy\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            model.eval()  # Set model to evaluation mode\n",
        "            with torch.no_grad():\n",
        "                for images, labels in test_loader:\n",
        "                    images = images.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    # Forward pass\n",
        "                    outputs = model(images)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                    # Update total and correct counts\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "            accuracy = 100 * correct / total\n",
        "            model.train()  # Set model back to training mode\n",
        "\n",
        "            # Print loss and accuracy\n",
        "            print(f\"Iteration: {iter}. Loss: {loss.item():.4f}. Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAUqqTzM3fF1",
        "outputId": "e591f487-2fa6-4e06-c0fd-7f754851689f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 500. Loss: 0.7318. Accuracy: 63.10%\n",
            "Iteration: 1000. Loss: 0.6159. Accuracy: 66.65%\n",
            "Iteration: 1500. Loss: 0.4628. Accuracy: 70.20%\n",
            "Iteration: 2000. Loss: 0.4138. Accuracy: 70.96%\n",
            "Iteration: 2500. Loss: 0.6070. Accuracy: 72.27%\n",
            "Iteration: 3000. Loss: 0.3003. Accuracy: 73.46%\n",
            "Iteration: 3500. Loss: 0.5483. Accuracy: 74.36%\n",
            "Iteration: 4000. Loss: 0.3384. Accuracy: 75.31%\n",
            "Iteration: 4500. Loss: 0.3838. Accuracy: 75.79%\n"
          ]
        }
      ]
    }
  ]
}